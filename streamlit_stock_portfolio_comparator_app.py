# -----------------------------------------------------------------------------
# IMPORTS & CONFIGURATION
# -----------------------------------------------------------------------------
import streamlit as st
import pandas as pd
import yfinance as yf
import numpy as np
import altair as alt
import plotly.express as px
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

# Page Config
st.set_page_config(page_title="SMI Pro Comparator", layout="wide", page_icon="üìà")

# -----------------------------------------------------------------------------
# GLOBAL CONSTANTS
# -----------------------------------------------------------------------------
SMI_COMPANIES = {
    "^SSMI": "üá®üá≠ SMI Index (Benchmark)",
    "ROG.SW": "Roche",
    "NESN.SW": "Nestl√©",
    "NOVN.SW": "Novartis",
    "UBSG.SW": "UBS Group",
    "ZURN.SW": "Zurich Insurance",
    "CFR.SW": "Richemont",
    "ABBN.SW": "ABB",
    "SIKA.SW": "Sika",
    "LONN.SW": "Lonza",
    "ALC.SW": "Alcon",
    "GIVN.SW": "Givaudan",
    "HOLN.SW": "Holcim",
    "SCMN.SW": "Swisscom",
    "PGHN.SW": "Partners Group",
    "SLHN.SW": "Swiss Life",
    "GEBN.SW": "Geberit",
    "SOON.SW": "Sonova",
    "SREN.SW": "Swiss Re",
    "KNIN.SW": "Kuehne + Nagel",
    "LOGN.SW": "Logitech"
}

# -----------------------------------------------------------------------------
# HELPER FUNCTIONS
# -----------------------------------------------------------------------------

def calculate_KPI(df, risk_free_rate=0.0):
    """
    Calculates detailed financial KPIs.
    Added 'risk_free_rate' parameter for more accurate Sharpe Ratio.
    """
    summary = pd.DataFrame(index=df.columns)
    
    # 1. Daily Returns
    returns = df.pct_change().dropna()
    
    # 2. Annualized Return (assuming 252 trading days)
    summary['Ann. Return'] = returns.mean() * 252

    # 3. Cumulative Return
    summary['Cumulative Return'] = (1 + returns).prod() - 1
    
    # 4. Annualized Volatility
    summary['Ann. Volatility'] = returns.std() * np.sqrt(252)
    
    # 5. Sharpe Ratio (Return - RiskFree) / Volatility
    summary['Sharpe Ratio'] = (summary['Ann. Return'] - risk_free_rate) / summary['Ann. Volatility']

    # 6. Sortino Ratio (Downside Deviation)
    target_return = 0
    downside_returns = returns.copy()
    downside_returns[downside_returns > target_return] = 0 # Replace positive returns with 0 for calculation
    annual_downside_vol = downside_returns.std() * np.sqrt(252)
    
    # Avoid division by zero
    summary['Sortino Ratio'] = np.where(
        annual_downside_vol == 0, 
        np.nan, 
        (summary['Ann. Return'] - risk_free_rate) / annual_downside_vol
    )
    
    # 7. Max Drawdown
    cumulative_returns_series = (1 + returns).cumprod()
    running_max = cumulative_returns_series.cummax()
    drawdown = (cumulative_returns_series / running_max) - 1
    summary['Max Drawdown'] = drawdown.min()

    # 8. Value at Risk (95%)
    summary['VaR (95%)'] = returns.quantile(0.05)
    
    return summary

def prepare_regression_data(series, window=21, horizon=1):
    """
    Prepares data for ML Volatility prediction.
    """
    if isinstance(series, pd.DataFrame):
        df = series.copy()
        df.columns = ['Close']
    else:
        df = series.to_frame(name='Close')
        
    df['Abs_Return'] = df['Close'].pct_change().abs()
    
    # Target Creation
    if horizon == 1:
        df['Target'] = df['Abs_Return'].shift(-1)
    else:
        indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=horizon)
        df['Target'] = df['Abs_Return'].rolling(window=indexer).mean()

    # Feature Engineering (Lags)
    for i in range(1, window + 1):
        df[f'Vol_Lag_{i}'] = df['Abs_Return'].shift(i)
    
    df = df.dropna()
    feature_cols = [f'Vol_Lag_{i}' for i in range(1, window + 1)]
    return df[feature_cols], df['Target']

@st.cache_data
def load_data(ticker_list, start_date):
    """
    Downloads data. Cached to prevent re-downloading on every slider change.
    We download from a fixed 'safe' start date to ensure ML has history.
    """
    if not ticker_list:
        return pd.DataFrame()
    
    try:
        data = yf.download(ticker_list, start=start_date, group_by='ticker', auto_adjust=True)
        
        # Handle MultiIndex / Single Index nuances of yfinance
        if len(ticker_list) == 1:
            # If single ticker, yf returns a simple dataframe, we just want Close
            return data['Close'].to_frame(name=ticker_list[0])
        else:
            # If multiple, it returns a MultiIndex (Ticker, OHLCV). We extract Close.
            # We iterate to robustly grab 'Close' for each ticker
            close_data = pd.DataFrame()
            for t in ticker_list:
                try:
                    close_data[t] = data[t]['Close']
                except KeyError:
                    st.warning(f"Could not find Close data for {t}")
            return close_data
            
    except Exception as e:
        st.error(f"Error downloading data: {e}")
        return pd.DataFrame()

# -----------------------------------------------------------------------------
# MAIN LAYOUT & SIDEBAR
# -----------------------------------------------------------------------------

st.title("üìà SMI Professional Portfolio Manager")

# --- SIDEBAR ---
with st.sidebar:
    st.header("üéõÔ∏è Configuration")
    
    # 1. Stock Selection
    selectable_tickers = [t for t in SMI_COMPANIES.keys() if t != "^SSMI"]
    
    tickers = st.multiselect(
        "Select Portfolio Assets", 
        options=selectable_tickers, 
        format_func=lambda x: f"{SMI_COMPANIES[x]} ({x})",
        default=["NESN.SW", "NOVN.SW", "UBSG.SW"]
    )
    
    # 2. Date Selection
    st.subheader("Time Horizon")
    col1, col2 = st.columns(2)
    start_date = col1.date_input("Start", value=pd.to_datetime("2020-01-01"))
    end_date = col2.date_input("End", value=pd.to_datetime("today"))
    
    # 3. Risk Free Rate
    rf_rate = st.number_input("Risk Free Rate (%)", value=1.0, step=0.1) / 100

    # 4. Portfolio Weights Logic
    st.markdown("---")
    st.header("‚öñÔ∏è Portfolio Allocation")
    
    weights = {}
    if tickers:
        with st.expander("Adjust Weights", expanded=True):
            # Helper to normalize weights if requested
            if st.button("Auto-Equalize Weights"):
                equal_weight = 100.0 / len(tickers)
                for t in tickers:
                    st.session_state[f"w_{t}"] = equal_weight
            
            total_weight = 0
            for t in tickers:
                # Key logic: Use session_state to allow programmatic updates (Auto-Equalize)
                key = f"w_{t}"
                if key not in st.session_state:
                    st.session_state[key] = 100.0 / len(tickers)
                
                weights[t] = st.number_input(
                    f"{SMI_COMPANIES[t]} (%)", 
                    min_value=0.0, max_value=100.0, 
                    step=1.0, 
                    key=key
                )
                total_weight += weights[t]

            # Dynamic Feedback
            diff = total_weight - 100.0
            if abs(diff) < 0.1:
                st.success(f"Total: {total_weight:.1f}% ‚úÖ")
            else:
                st.error(f"Total: {total_weight:.1f}% (Diff: {diff:.1f}%) ‚ùå")


# -----------------------------------------------------------------------------
# DATA LOADING & PROCESSING
# -----------------------------------------------------------------------------

# Download ample history for ML, filter later for display
# We go back 2 years + 1 month from the user's start date to ensure lags work
buffer_date = pd.Timestamp(start_date) - pd.DateOffset(years=2)
tickers_to_load = list(set(tickers + ["^SSMI"]))

full_data = load_data(tickers_to_load, buffer_date)

if full_data.empty:
    st.warning("No data loaded. Please check your internet connection or ticker selection.")
    st.stop()

# -----------------------------------------------------------------------------
# PORTFOLIO CALCULATION
# -----------------------------------------------------------------------------
cleaned_df = full_data.dropna()

# Calculate Portfolio logic if weights are valid
has_portfolio = False
if tickers and abs(sum(weights.values()) - 100.0) < 0.1:
    has_portfolio = True
    
    # Isolate selected stocks
    selection = cleaned_df[tickers]
    
    # Calculate weighted returns
    # Formula: Sum(Weight * DailyReturn) for each day
    w_list = [weights[t] / 100.0 for t in tickers]
    portfolio_daily_ret = selection.pct_change().dot(w_list)
    
    # Create Index (Start at 100)
    portfolio_idx = (1 + portfolio_daily_ret).cumprod() * 100
    portfolio_idx.iloc[0] = 100
    
    cleaned_df["üíº My Portfolio"] = portfolio_idx

# -----------------------------------------------------------------------------
# FILTERING FOR DISPLAY
# -----------------------------------------------------------------------------
# Now we cut the dataframe to the user's specific requested date range
mask = (cleaned_df.index >= pd.Timestamp(start_date).tz_localize(None)) & \
       (cleaned_df.index <= pd.Timestamp(end_date).tz_localize(None))
display_df = cleaned_df.loc[mask]

if display_df.empty:
    st.error("Selected date range resulted in empty data (maybe weekends/holidays selected?).")
    st.stop()

# -----------------------------------------------------------------------------
# VISUALIZATION TAB
# -----------------------------------------------------------------------------
tab1, tab2, tab3 = st.tabs(["üìä Performance & Charts", "üìâ Risk & Correlation", "ü§ñ AI Volatility Predictor"])

with tab1:
    # --- MAIN CHART (Plotly) ---
    st.subheader("Price Evolution (Indexed to 100)")
    
    # Normalize data to start at 100 for comparison
    normalized_df = display_df / display_df.iloc[0] * 100
    
    # Convert to long format for Plotly
    plot_data = normalized_df.reset_index().melt('Date', var_name='Asset', value_name='Normalized Price')
    
    # Map ticker symbols to readable names for the legend
    # We create a temporary mapping including 'My Portfolio'
    legend_map = SMI_COMPANIES.copy()
    legend_map["üíº My Portfolio"] = "üíº My Portfolio"
    plot_data['Asset Name'] = plot_data['Asset'].map(lambda x: legend_map.get(x, x))

    fig = px.line(
        plot_data, 
        x="Date", y="Normalized Price", color="Asset Name",
        hover_data={"Date": "|%B %d, %Y"},
        title="Comparative Performance"
    )
    fig.update_layout(hovermode="x unified")
    st.plotly_chart(fig, use_container_width=True)

    # --- RAW DATA DOWNLOAD ---
    with st.expander("See Raw Data"):
        st.dataframe(display_df.tail(10))
        st.download_button(
            "Download CSV", 
            display_df.to_csv().encode('utf-8'), 
            "portfolio_data.csv", 
            "text/csv"
        )

with tab2:
    col1, col2 = st.columns([1, 1])
    
    # --- KPI TABLE ---
    with col1:
        st.subheader("Financial KPIs")
        kpi_df = calculate_KPI(display_df, risk_free_rate=rf_rate)
        
        # Formatting for display
        format_dict = {
            'Ann. Return': '{:.2%}',
            'Cumulative Return': '{:.2%}',
            'Ann. Volatility': '{:.2%}',
            'Sharpe Ratio': '{:.2f}',
            'Sortino Ratio': '{:.2f}',
            'Max Drawdown': '{:.2%}',
            'VaR (95%)': '{:.2%}'
        }
        
        # Highlight the Portfolio row if it exists
        st.dataframe(kpi_df.style.format(format_dict).apply(
            lambda x: ['background: #e6f3ff' if x.name == "üíº My Portfolio" else '' for i in x], axis=1
        ))

    # --- CORRELATION MATRIX ---
    with col2:
        st.subheader("Correlation Matrix")
        st.caption("How much do assets move together? (1.0 = identical, 0.0 = unrelated)")
        
        if tickers:
            # Only correlate selected tickers (exclude index and portfolio for clarity if desired)
            corr_df = display_df[tickers].pct_change().corr()
            
            # Use readable names for axis
            corr_df.index = corr_df.index.map(lambda x: SMI_COMPANIES.get(x, x))
            corr_df.columns = corr_df.columns.map(lambda x: SMI_COMPANIES.get(x, x))
            
            fig_corr = px.imshow(
                corr_df, 
                text_auto='.2f', 
                aspect="auto", 
                color_continuous_scale='RdBu_r',
                zmin=-1, zmax=1
            )
            st.plotly_chart(fig_corr, use_container_width=True)
        else:
            st.info("Select stocks to see correlation.")

    # --- RISK/RETURN SCATTER ---
    st.subheader("Risk vs. Return Landscape")
    
    # Prepare data for scatter
    scatter_data = kpi_df.reset_index().rename(columns={'index': 'Asset'})
    scatter_data['Asset Name'] = scatter_data['Asset'].map(lambda x: legend_map.get(x, x))
    
    fig_scatter = px.scatter(
        scatter_data,
        x="Ann. Volatility",
        y="Ann. Return",
        color="Asset Name",
        size="Sharpe Ratio", # Bubble size based on efficiency
        text="Asset Name",
        hover_data=["Max Drawdown", "Sharpe Ratio"],
        title="Risk (Volatility) vs Return"
    )
    # Add crosshairs at 0
    fig_scatter.add_hline(y=0, line_dash="dash", line_color="gray")
    fig_scatter.add_vline(x=0, line_dash="dash", line_color="gray")
    fig_scatter.update_traces(textposition='top center')
    st.plotly_chart(fig_scatter, use_container_width=True)

with tab3:
    st.subheader("ü§ñ AI Volatility Forecast")
    st.write("Using **Random Forest Regression** to predict future market turbulence based on recent patterns.")
    
    col_ml_1, col_ml_2 = st.columns(2)
    
    with col_ml_1:
        # Filter options to only actual tickers (exclude Portfolio/Index usually, or keep them)
        ml_options = list(display_df.columns)
        ml_ticker = st.selectbox("Select Asset to Predict", ml_options, format_func=lambda x: legend_map.get(x, x))
    
    with col_ml_2:
        horizon_map = {"Next Day": 1, "Next Week (5 Days)": 5, "Next Month (21 Days)": 21}
        horizon_lbl = st.selectbox("Prediction Horizon", list(horizon_map.keys()))
        horizon_val = horizon_map[horizon_lbl]

    if st.button("Train Model & Predict"):
        with st.spinner("Training Random Forest Model..."):
            # Use CLEANED_DF (full history) for training, not just display slice
            series = cleaned_df[ml_ticker]
            X, y = prepare_regression_data(series, window=21, horizon=horizon_val)
            
            if len(X) > 100:
                # 80/20 Split
                split = int(len(X) * 0.8)
                X_train, X_test = X.iloc[:split], X.iloc[split:]
                y_train, y_test = y.iloc[:split], y.iloc[split:]
                
                # Model
                model = RandomForestRegressor(n_estimators=100, random_state=42)
                model.fit(X_train, y_train)
                
                # Evaluation
                preds = model.predict(X_test)
                mae = mean_absolute_error(y_test, preds)
                
                # Future Prediction (using the very latest available data points)
                latest_features = X.iloc[-1:].values
                future_pred = model.predict(latest_features)[0]
                
                # --- RESULTS ---
                c1, c2, c3 = st.columns(3)
                c1.metric(f"Predicted Volatility ({horizon_lbl})", f"{future_pred:.2%}")
                c2.metric("Model Accuracy (MAE)", f"{mae:.2%}", delta_color="inverse")
                c3.metric("Current Hist. Volatility (Last 21d)", f"{series.pct_change().abs().tail(21).mean():.2%}")
                
                # Plot Actual vs Predicted on Test Set
                res_df = pd.DataFrame({'Actual': y_test, 'Predicted': preds}, index=y_test.index)
                
                fig_ml = px.line(res_df, title="Model Validation: Actual vs Predicted Volatility (Test Set)")
                st.plotly_chart(fig_ml, use_container_width=True)
                
            else:
                st.error("Not enough historical data to train model. Try selecting an older start date.")
